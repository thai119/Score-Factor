{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../config.yaml\", \"r\") as yamlfile:\n",
    "    cfg = yaml.safe_load(yamlfile)\n",
    "\n",
    "for section in cfg:\n",
    "    RANDOM_STATE_SEED = cfg[\"variables\"][\"RANDOM_STATE_SEED\"]\n",
    "    THRESHOLD = cfg[\"variables\"][\"THRESHOLD\"]\n",
    "    THRESHOLD_LOSS = cfg[\"variables\"][\"THRESHOLD_LOSS\"]\n",
    "\n",
    "    PROCESSED_DATA_DIR = cfg[\"data_path\"][\"PROCESSED_DATA_DIR\"]\n",
    "\n",
    "DATA_DIR = 'D:/code/gr1/data/unraveled/data/network_flows'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_paths = [os.path.join(DATA_DIR,  dataset_path) for dataset_path in os.listdir(DATA_DIR)]\n",
    "all_csv_files = []\n",
    "for dataset_path in dataset_paths:\n",
    "    csv_files_directory = glob.glob(dataset_path + '/*.csv')\n",
    "    all_csv_files.extend(csv_files_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('D:/code/gr1/data/dataset/unraveled_defender_response.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "unique_stages = df['Stage'].unique()\n",
    "print(f\"Các giá trị duy nhất trong cột 'Stage': {unique_stages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "list_features = [\n",
    "    'bidirectional_duration_ms', 'src2dst_duration_ms',\n",
    "    'dst2src_duration_ms', 'src2dst_packets', 'dst2src_packets',\n",
    "    'src2dst_bytes', 'dst2src_bytes', 'src2dst_max_ps', 'src2dst_min_ps',\n",
    "    'src2dst_mean_ps', 'src2dst_stddev_ps', 'dst2src_max_ps', 'dst2src_min_ps',\n",
    "    'dst2src_mean_ps', 'dst2src_stddev_ps', 'bidirectional_mean_piat_ms',\n",
    "    'bidirectional_stddev_piat_ms', 'bidirectional_max_piat_ms', \n",
    "    'bidirectional_min_piat_ms','src2dst_mean_piat_ms', 'src2dst_stddev_piat_ms', \n",
    "    'src2dst_max_piat_ms', 'src2dst_min_piat_ms', 'dst2src_mean_piat_ms',\n",
    "    'dst2src_stddev_piat_ms', 'dst2src_max_piat_ms', 'dst2src_min_piat_ms', \n",
    "    'bidirectional_fin_packets', 'src2dst_fin_packets', 'dst2src_fin_packets', \n",
    "    'bidirectional_syn_packets', 'src2dst_syn_packets', 'dst2src_syn_packets',\n",
    "    'bidirectional_rst_packets', 'src2dst_rst_packets', 'dst2src_rst_packets',\n",
    "    'bidirectional_psh_packets', 'src2dst_psh_packets', 'dst2src_psh_packets', \n",
    "    'bidirectional_ack_packets', 'src2dst_ack_packets', 'dst2src_ack_packets', \n",
    "    'bidirectional_urg_packets', 'src2dst_urg_packets', \n",
    "    'bidirectional_cwr_packets', 'src2dst_cwr_packets', \n",
    "    'bidirectional_ece_packets', 'src2dst_ece_packets', 'Stage'\n",
    "]\n",
    "\n",
    "df = df[list_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử stage_mapping là từ điển mà bạn đã định nghĩa\n",
    "stage_mapping = {\n",
    "    'Benign': 0,        \n",
    "    'Reconnaissance': 1,     \n",
    "    'Establish Foothold': 2,\n",
    "    'Lateral Movement': 3,\n",
    "    'Data Exfiltration': 4,\n",
    "    'Cover up': 5\n",
    "}\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Giả sử df là DataFrame đã đọc từ một tập tin CSV và có cột 'Stage'\n",
    "# In ra các giá trị duy nhất trong cột 'Stage'\n",
    "unique_stages = df['Stage'].unique()\n",
    "print(f\"Các giá trị duy nhất trong cột 'Stage': {unique_stages}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Đếm số lượng mẫu cho từng nhãn\n",
    "stage_counts = df['Stage'].value_counts().sort_index()\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(stage_counts.index, stage_counts.values, color='skyblue', alpha=0.8)\n",
    "\n",
    "# Thêm nhãn, tiêu đề và lưới\n",
    "plt.title('Distribution of Stages', fontsize=16)\n",
    "plt.xlabel('Stage', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(ticks=stage_counts.index, labels=[\n",
    "    'Benign',\n",
    "    'Reconnaissance',\n",
    "    'Establish Foothold',\n",
    "    'Lateral Movement',\n",
    "    'Data Exfiltration',\n",
    "    'Cover up'\n",
    "], rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Định nghĩa số lượng mẫu mong muốn cho từng nhãn\n",
    "desired_samples = {\n",
    "    0: 500,\n",
    "    1: 3000,\n",
    "    2: 3000,\n",
    "    3: 1000,\n",
    "    4: 1000,\n",
    "    5: 359\n",
    "}\n",
    "\n",
    "# Chia dữ liệu thành từng nhãn và resample theo số lượng mong muốn\n",
    "df_balanced = pd.concat([\n",
    "    resample(\n",
    "        df[df['Stage'] == stage],\n",
    "        replace=False,  # Không thay thế\n",
    "        n_samples=desired_samples[stage],  # Số lượng mẫu mong muốn\n",
    "        random_state=42\n",
    "    )\n",
    "    for stage in desired_samples.keys()\n",
    "])\n",
    "\n",
    "# Kiểm tra kết quả\n",
    "print(df_balanced['Stage'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "# Tăng số lượng nhãn 5 lên (oversampling)\n",
    "desired_samples_for_label_5 = 1000  # Số lượng mong muốn cho nhãn 5\n",
    "df_label_5 = df_balanced[df_balanced['Stage'] == 5]  # Lấy các mẫu của nhãn 5\n",
    "\n",
    "df_label_5_oversampled = resample(\n",
    "    df_label_5,\n",
    "    replace=True,  # Cho phép nhân bản\n",
    "    n_samples=desired_samples_for_label_5,  # Tăng lên số lượng mong muốn\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Kết hợp lại toàn bộ dữ liệu\n",
    "df_balanced_final = pd.concat([\n",
    "    df_balanced[df_balanced['Stage'] != 5],  # Các nhãn khác\n",
    "    df_label_5_oversampled  # Nhãn 5 đã oversample\n",
    "])\n",
    "\n",
    "# Kiểm tra kết quả cuối cùng\n",
    "print(df_balanced_final['Stage'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "X = df_balanced.drop('Stage', axis=1)\n",
    "y = df_balanced['Stage']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "xgb_apt2021 = xgb.XGBClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xgb_apt2021.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = xgb_apt2021.predict(x_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
